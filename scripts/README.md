## Generating vision module datasets

First, here is a changelog of dataset versions and the diffs between successive
versions:

- `planning_v003` and `placing_v003` (April 17, 2020)
  - Change the camera "look at" locations:
    - `planning_v003`: Instead of looking at every single object, look once at the center of the distribution of object locations and heights.
    - `placing_v003`: Instead of looking at every single object, look once at the top of the bottom object.
  - FIX: Shadow bias is removed, now shadow and object are joined instead of 
  having a gap between them.
- `dash_v005` (April 14, 2020)
  - Changed from `placing_v002` (100 trials) to `placing_v003` (1500 trials).
  - Changed from 50/50 split between planning and placing to 25/75 split.
- `dash_v004` (Apr 13, 2020)
  - Update to use Yifeng's new placing policy: `0404_0_n_20_40`.
  - Changed from `placing.sh` to `placing_v002.sh`.
- `dash_v003`: 
  - FIX: Update the transformation of y labels (specifically, position and 
  orientation of objects) from the incorrect bworld -> ucam to the correct 
  bworld -> bshoulder -> ushoulder -> ucam transformation.
  - FIX: Images; Unity delayed rendering vs. snapshot where arm was never 
    really holding any objects before.
  - FIX: Bug where saved camera orientation is changed from xyyw -> xyzw.
- `dash_v002`: The first dataset to train both planning and placing, together.

Step 1. Generate states for planning and placing. (ETA: 40 minutes)

```
time ./ns_vqa_dart/scripts/planning_v003_20K/01_generate_states.sh
time ./ns_vqa_dart/scripts/placing_v003_2K_100/01_generate_states.sh
```

Step 2. On the Unity machine, run the following to transfer the states to the
Unity machine.
(ETA: 1 minute 22 seconds)

```
time ./ns_vqa_dart/scripts/planning_v003_20K/02_transfer_states.sh
time ./ns_vqa_dart/scripts/placing_v003_100/02_transfer_states.sh
```

Step 3. Generate Unity images from the states, and transfer the images to the 
machine where training will occur. 

(ETA: 1 hour 30 minutes for generation, 3 
hours for transfer)

Note: Currently you need to update the `end_id` of the `DatasetLoader` in the
script.

```
time ./ns_vqa_dart/scripts/planning_v003_20K/03_generate_unity_images.sh
time ./ns_vqa_dart/scripts/placing_v003_100/03_generate_unity_images.sh
```

Step 4. Generate the dataset and run training and evaluation.

ETA: 30 minutes for generation, 3 hours for training
WARNING: Make sure sydney has enough space before running this! Roughly 120 GB
of space is needed.


```
time ./ns_vqa_dart/scripts/planning_v003_20K/04_generate_and_run.sh
./ns_vqa_dart/scripts/placing_v003_100/04_generate_and_run.sh
```

## To visualize results in an HTML webpage

Start the server:
```
cd /media/michelle/68B62784B62751BC/html
python -m http.server
```

## Generating result tables

### Table 1: Results on the full system

Below are instructions on how to generate a demo video of Lucas.

Step 1. First, follow instructions below on running reaching and transporting
OpenRAVE programs in docker containers.

Step 2. Run the following bash script to generate the demos.
```
./scripts/table1/gv5_pv9_gt_delay.sh
```

Step 3. Transfer the poses to the machine where Unity will be run.
```
rsync -azP ~/demo_poses ~/workspace/lucas/
```

### Table 2: Results on stacking

```
# Ground truth
./scripts/table2/delay_box.sh
./scripts/table2/delay_cyl.sh

# Vision module
./scripts/table2/delay_vision_box.sh
./scripts/table2/delay_vision_cyl.sh

# Baseline
./scripts/table2/baseline_box.sh
./scripts/table2/baseline_cyl.sh
```

## NLP-related installation instructions

Mainly to run `main_sim_stack_new.py`:

```
pip install spacy nltk
python -m spacy download en_core_web_sm
```

## Instructions for Building & Running OpenRAVE:

First, build the image.

```
git clone git@github.com:jyf588/openrave-installation.git
cd openrave-installation
git checkout my_docker
cd nvidia-docker
sudo docker build -t openrave-ha:v0 .
cd ../openrave-docker
sudo docker build -t openrave-ha:v2 .
cd ../or-my-docker
sudo docker build -t openrave-ha:v3 .
```

Next, run the container of the built image:
(create a container with access to data from the host machine create a folder "container_data" in the home directory)

```
xhost +si:localuser:root
sudo docker run --gpus=all -ti --rm -e DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix -v ~/container_data:/data --name openravecont openrave-ha:v3 /bin/bash
```

Troubleshooting
```
>>> docker: Error response from daemon: could not select device driver "" with capabilities: [[gpu]].
```
Solution: https://devtalk.nvidia.com/default/topic/1061452/docker-and-nvidia-docker/could-not-select-device-driver-quot-quot-with-capabilities-gpu-/

Inside the running container, see if you can use Firefox and openrave with GUI.
```
source bashrc
glxgears
firefox
```

To run openrave examples: (https://scaron.info/teaching/installing-openrave-on-ubuntu-14.04.html)
```
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$(openrave-config --python-dir)/openravepy/_openravepy_
export PYTHONPATH=$PYTHONPATH:$(openrave-config --python-dir)
openrave.py --example hanoi
```

Other useful docker commands (with sudo): 

```
docker ps --all (list containers)
docker rm -f contrainer_number (kill and remove container)
docker image list
docker image rm image_number
docker cp <src_path> openravecont:<dst_path>
```

To run OpenRAVE for DASH:

Outside of docker container:
```
cd ~/container_data
git clone https://github.com/jyf588/or_planning_scripts
```

Update `tabletop_2.kinbody.xml` to the following:

```
<KinBody name="box0">
  <Body name="base">
    <Geom type="box">
      <extents>1.3 0.6 0.05</extents>
      <translation>0.2 0.1 -0.13</translation>
      <diffusecolor>0.6 0 0</diffusecolor>
    </Geom>
  </Body>
</KinBody>
```

Inside of docker container, run the following to run reaching:
```
source bashrc
cd /data/or_planning_scripts
python move_single.py 0
```

Start a second docker container session to run transport:
If you need to run reach_single.py also, open another session for the same 
container:
```
sudo docker exec -it openravecont /bin/bash
source bashrc
cd /data/or_planning_scripts
python move_single.py 1
```

First time running the scripts will take a few minutes. (Usually when yellow
output shows up)

April 15, 2020: Re-ran `sudo docker build -t openrave-ha:v3 .` with 
the following command (because `inmoov.git` was updated):
```
sudo docker build --no-cache -t openrave-ha:v3 .
```
And then restarted both containers.
